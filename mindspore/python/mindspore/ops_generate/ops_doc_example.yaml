bias_add:
    description: |    
        Returns the sum of the input tensor and the bias tensor. Before adding, the bias tensor will be broadcasted to be
            consistent with the shape of the input tensor.

            Args:
            data_format (str, optional): The format of input and output data.
            It should be "NHWC", "NCHW" or "NCDHW".
            Default is "NCHW".
            input_x (tensor) - The input tensor. The shape can be 2-5 dimensions.
            bias (tensor) - The bias tensor, with shape (C). C must be the same as channel dimension C of
            `input_x`.

            Returns:
            tensor, with the same shape and data type as `input_x`.

            Raises:
            TypeError: If `data_format` is not a str.
            ValueError: If value of `data_format` is not in the range of ['NHWC','NCHW','NCDHW'].
            TypeError: If `input_x` or `bias` is not a tensor.
            TypeError: If dtype of `input_x` or `bias` is inconsistent.
            TypeError: If dimension of `input_x` is not in the range [2, 5].

            Supported Platforms:
            "Ascend", "GPU", "CPU"

            Examples:
            >>> import mindspore
            >>> import numpy as np
            >>> from mindspore import tensor, ops
            >>> input_x = tensor(np.arange(6).reshape((2, 3)), mindspore.float32)
            >>> bias = tensor(np.random.random(3).reshape((3,)), mindspore.float32)
            >>> bias_add = ops.BiasAdd()
            >>> output = bias_add(input_x, bias)
            >>> print(output.shape)
            (2, 3)

batch_norm:
    description: |
        Batch Normalization for input data and updated parameters.

            Batch Normalization is widely used in convolutional neural networks. This operation
            applies Batch Normalization over inputs to avoid internal covariate shift as described
            in the paper `Batch Normalization: Accelerating Deep Network Training by Reducing Internal
            Covariate Shift <https://arxiv.org/abs/1502.03167>`_. It rescales and recenters the
            features using a mini-batch of data and the learned parameters can be described
            in the following formula,

            .. math::

                y = \frac{x - mean}{\sqrt{variance + \epsilon}} * \gamma + \beta

            where :math:`\gamma` is `weight`, :math:`\beta` is `bias`, :math:`\epsilon` is `eps`, :math:`mean` is the
            mean of `x`, :math:`variance` is the variance of `x`.

            .. warning::
                - For Ascend 310, the result accuracy fails to reach 1â€° due to the square root instruction.

            Note:
                - If `training` is `False`, `weight`, `bias`, `running_mean` and `running_var` are tensors.
                - If `training` is `True`, `weight`, `bias`, `running_mean` and `running_var` are Parameters.

            Args:
                input_x (tensor): tensor of shape :math:`(N, C)`, with float16 or float32 data type.
                running_mean (Union[tensor, Parameter]): The shape :math:`(C,)`, has the same data type with `weight`.
                running_var (Union[tensor, Parameter]): The shape :math:`(C,)`, has the same data type with `weight`.
                weight (Union[tensor, Parameter]): The shape :math:`(C,)`, with float16 or float32 data type.
                bias (Union[tensor, Parameter]): The shape :math:`(C,)`, has the same data type with `weight`.
                training (bool, optional): If `training` is `True`, `mean` and `variance` are computed during training.
                    If `training` is `False`, they're loaded from checkpoint during inference. Default: False.
                momentum (float, optional): The hyper parameter to compute moving average for `running_mean` and `running_var`
                    (e.g. :math:`new\_running\_mean = (1 - momentum) * running\_mean + momentum * current\_mean`).
                    Momentum value must be `[0, 1]`. Default: 0.1.
                eps (float, optional): A small value added for numerical stability. Default: 1e-5, value must be `(0, 1]`.

            Returns:
                output_x (tensor) - The same type and shape as the `input_x`. The shape is :math:`(N, C)`.

            Raises:
                TypeError: If `training` is not a bool.
                TypeError: If dtype of `eps` or `momentum` is not float.
                TypeError: If `input_x`, `weight`, `bias`, `running_mean` or `running_var` is not a tensor.
                TypeError: If dtype of `input_x`, `weight` is neither float16 nor float32.

            Supported Platforms:
                ``Ascend`` ``GPU`` ``CPU``

            Examples:
                >>> input_x = tensor([[1.0, 2.0], [3.0, 4.0]], mindspore.float32)
                >>> running_mean = tensor([0.5, 1.5], mindspore.float32)
                >>> running_var = tensor([0.1, 0.2], mindspore.float32)
                >>> weight = tensor([2.0, 2.0], mindspore.float32)
                >>> bias = tensor([-1.0, -1.0], mindspore.float32)
                >>> output = ops.batch_norm(input_x, running_mean, running_var, weight, bias)
                >>> print(output)
                [[ 2.1621194  1.2360122]
                [14.810596  10.180061 ]]

avg_pool:
    description: |
        Average pooling operation.

            Args:
                x (Tensor): Tensor of shape :math:`(N, C_{in}, H_{in}, W_{in})`.
                kernel_size (Union[int, tuple[int]]): The size of kernel used to take the average value,
                    is an int number that represents height and width of the kernel, or a tuple
                    of two int numbers that represent height and width respectively. Default: 1.
                strides (Union[int, tuple[int]]): The distance of kernel moving, an int number that represents
                    the height and width of movement are both strides, or a tuple of two int numbers that
                    represent height and width of movement respectively. Default: 1.
                pad_mode (str): The optional value for pad mode, is 'same' or 'valid'.
                    Default: 'valid'.

                    - same: The height and width of the output are the same as the input divided by 'strides'
                    and rounded up.

                    - valid: Returns the output of the valid calculation without filling. Redundant pixels that
                    do not satisfy the calculation will be discarded.
                data_format (str): The format of input and output data. It should be 'NHWC' or 'NCHW'.
                    Default: 'NCHW'.

            Returns:
                output(Tensor), with shape :math:`(N, C_{out}, H_{out}, W_{out})`.

            Raises:
                TypeError: If `kernel_size` or `strides` is neither int nor tuple.
                ValueError: If `kernel_size` or `strides` is less than 1.
                ValueError: If `pad_mode` is neither 'valid' nor 'same' with not case sensitive.
                ValueError: If `data_format` is neither 'NCHW' nor 'NHWC'.
                ValueError: If length of shape of `x` is not equal to 4.

            Supported Platforms:
                ``Ascend`` ``GPU`` ``CPU``

            Examples:
                >>> class Net(nn.Cell):
                ...     def __init__(self):
                ...         super(Net, self).__init__()
                ...         self.avgpool_op = ops.AvgPool(pad_mode="VALID", kernel_size=2, strides=1)
                ...
                ...     def construct(self, x):
                ...         result = self.avgpool_op(x)
                ...         return result
                ...
                >>> x = Tensor(np.arange(1 * 3 * 3 * 4).reshape(1, 3, 3, 4), mindspore.float32)
                >>> net = Net()
                >>> output = net(x)
                >>> print(output)
                [[[[ 2.5   3.5   4.5]
                [ 6.5   7.5   8.5]]
                [[14.5  15.5  16.5]
                [18.5  19.5  20.5]]
                [[26.5  27.5  28.5]
                [30.5  31.5  32.5]]]]